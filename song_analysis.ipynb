{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Spotify Songs\n",
    "\n",
    "The aim of this work is to analyse music. Utilizing the acoustic features that Spotify provides for songs, we will look into a couple of data mining algorithms, namely popularity and genre prediction, and provide some interesting visualizations, about some fun aspects of music and some intertemporal trends.\n",
    "\n",
    "In this work, a couple of datasets that contain information about a sample of hundreds of thousands of songs that are currently on Spotify will be used, in conjuction with the API that Spotify provides.\n",
    "\n",
    "Author: nantoniou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "First of all we will need to find a rich and robust data source. We will combine two; [the first one](https://www.kaggle.com/zaheenhamidani/ultimate-spotify-tracks-db) (`SpotifyFeatures.csv`) is from Kaggle and [the second one](https://components.one/datasets/billboard-200/) (`billboard-200.db`) is from the `components.one` website.\n",
    "\n",
    "* The first one contains 232.725 songs and has the advantage of having an equal number of songs from each genre. It contains:\n",
    " * basic song meta-data (genre, artist_name, track_name, track_id),\n",
    " * the song's popularity,\n",
    " * each song's audio features (some documentation can be found [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)), which basically allow us to analyse the musical characteristics of the songs, such as danceability, energy, loudness and valence.\n",
    "\n",
    "* The second one has 340.000 songs, with similar features, but it also includes some information about the each song's album and the release date of the song. However, it does not include the song's genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "data = pd.read_csv('SpotifyFeatures.csv')\n",
    "\n",
    "cnx = sqlite3.connect('billboard-200.db')\n",
    "data2 = pd.read_sql_query(\"SELECT * FROM acoustic_features\", cnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data merging\n",
    "\n",
    "We want to merge those data sources into one, but, as we can see below, the songs that are found in both of the datasets are few (only 69.884). Thus, we will use another method below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69884"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data.track_id.isin(data2.id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "We can see that the songs go as far back as 1900!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1900'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.date.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Song duplicates\n",
    "\n",
    "The first data source has 91.075 duplicate songs. That is due to the fact that songs have a different record in the table for every genre they belong in.\n",
    "\n",
    "The second data source has zero duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.track_id.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.id.duplicated(keep=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Albums\n",
    "\n",
    "Let us also take a look into the albums database, that the second data source provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rank</th>\n",
       "      <th>length</th>\n",
       "      <th>track_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>185233.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>21 Savage</td>\n",
       "      <td>I Am &gt; I Was</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>211050.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Soundtrack</td>\n",
       "      <td>Spider-Man: Into The Spider-Verse</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>190866.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Meek Mill</td>\n",
       "      <td>Championships</td>\n",
       "      <td>4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>219173.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>beerbongs &amp; bentleys</td>\n",
       "      <td>5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>214113.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date                  artist                              album  \\\n",
       "1   2  2019-01-19  A Boogie Wit da Hoodie                         Hoodie SZN   \n",
       "2   3  2019-01-19               21 Savage                       I Am > I Was   \n",
       "3   4  2019-01-19              Soundtrack  Spider-Man: Into The Spider-Verse   \n",
       "4   5  2019-01-19               Meek Mill                      Championships   \n",
       "5   6  2019-01-19             Post Malone               beerbongs & bentleys   \n",
       "\n",
       "  rank  length   track_length  \n",
       "1    1    20.0  185233.800000  \n",
       "2    2    15.0  211050.733333  \n",
       "3    3    13.0  190866.384615  \n",
       "4    4    19.0  219173.894737  \n",
       "5    5    18.0  214113.611111  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albums = pd.read_sql_query(\"SELECT * FROM albums\", cnx)\n",
    "albums.drop(0, inplace=True)\n",
    "albums.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 339.855 out of 573.946 albums have songs in the songs table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>album_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0Veyvc3n9AcLSoK3r1dA12</td>\n",
       "      <td>Voices In My Head</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.754</td>\n",
       "      <td>142301.0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-6.311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>90.195</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.207</td>\n",
       "      <td>3r5hf3Cj3EMh1C2saQ8jyt</td>\n",
       "      <td>2018-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77JzXZonNumWsuXKy9vr3U</td>\n",
       "      <td>Beasty</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.860</td>\n",
       "      <td>152829.0</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-9.061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158</td>\n",
       "      <td>126.023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.374</td>\n",
       "      <td>3r5hf3Cj3EMh1C2saQ8jyt</td>\n",
       "      <td>2018-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18yllZD0TdF7ykcREib8Z1</td>\n",
       "      <td>I Did It</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.718</td>\n",
       "      <td>215305.0</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-9.012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127</td>\n",
       "      <td>89.483</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.196</td>\n",
       "      <td>3r5hf3Cj3EMh1C2saQ8jyt</td>\n",
       "      <td>2018-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1wJRveJZLSb1rjhnUHQiv6</td>\n",
       "      <td>Swervin (feat. 6ix9ine)</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.581</td>\n",
       "      <td>189487.0</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-5.239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.303</td>\n",
       "      <td>93.023</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>3r5hf3Cj3EMh1C2saQ8jyt</td>\n",
       "      <td>2018-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0jAfdqv18goRTUxm3ilRjb</td>\n",
       "      <td>Startender (feat. Offset and Tyga)</td>\n",
       "      <td>Hoodie SZN</td>\n",
       "      <td>A Boogie Wit da Hoodie</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.736</td>\n",
       "      <td>192779.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-4.653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>191.971</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.506</td>\n",
       "      <td>3r5hf3Cj3EMh1C2saQ8jyt</td>\n",
       "      <td>2018-12-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                song       album  \\\n",
       "0  0Veyvc3n9AcLSoK3r1dA12                   Voices In My Head  Hoodie SZN   \n",
       "1  77JzXZonNumWsuXKy9vr3U                              Beasty  Hoodie SZN   \n",
       "2  18yllZD0TdF7ykcREib8Z1                            I Did It  Hoodie SZN   \n",
       "3  1wJRveJZLSb1rjhnUHQiv6             Swervin (feat. 6ix9ine)  Hoodie SZN   \n",
       "4  0jAfdqv18goRTUxm3ilRjb  Startender (feat. Offset and Tyga)  Hoodie SZN   \n",
       "\n",
       "                   artist  acousticness  danceability  duration_ms  energy  \\\n",
       "0  A Boogie Wit da Hoodie        0.0555         0.754     142301.0   0.663   \n",
       "1  A Boogie Wit da Hoodie        0.2920         0.860     152829.0   0.418   \n",
       "2  A Boogie Wit da Hoodie        0.1530         0.718     215305.0   0.454   \n",
       "3  A Boogie Wit da Hoodie        0.0153         0.581     189487.0   0.662   \n",
       "4  A Boogie Wit da Hoodie        0.0235         0.736     192779.0   0.622   \n",
       "\n",
       "   instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
       "0          0.000000  6.0     0.101    -6.311   0.0        0.427   90.195   \n",
       "1          0.000000  7.0     0.106    -9.061   0.0        0.158  126.023   \n",
       "2          0.000046  8.0     0.116    -9.012   1.0        0.127   89.483   \n",
       "3          0.000000  9.0     0.111    -5.239   1.0        0.303   93.023   \n",
       "4          0.000000  6.0     0.151    -4.653   0.0        0.133  191.971   \n",
       "\n",
       "   time_signature  valence                album_id        date  \n",
       "0             4.0    0.207  3r5hf3Cj3EMh1C2saQ8jyt  2018-12-21  \n",
       "1             4.0    0.374  3r5hf3Cj3EMh1C2saQ8jyt  2018-12-21  \n",
       "2             4.0    0.196  3r5hf3Cj3EMh1C2saQ8jyt  2018-12-21  \n",
       "3             4.0    0.434  3r5hf3Cj3EMh1C2saQ8jyt  2018-12-21  \n",
       "4             4.0    0.506  3r5hf3Cj3EMh1C2saQ8jyt  2018-12-21  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.loc[data2.album.isin(albums.album)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sample statistic, we can see that the mean song popularity is 41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.12750241701579"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.popularity.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, merging the two data sources greatly reduces our dataset's records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>acousticness_x</th>\n",
       "      <th>danceability_x</th>\n",
       "      <th>duration_ms_x</th>\n",
       "      <th>energy_x</th>\n",
       "      <th>instrumentalness_x</th>\n",
       "      <th>key_x</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_y</th>\n",
       "      <th>instrumentalness_y</th>\n",
       "      <th>key_y</th>\n",
       "      <th>liveness_y</th>\n",
       "      <th>loudness_y</th>\n",
       "      <th>mode_y</th>\n",
       "      <th>speechiness_y</th>\n",
       "      <th>tempo_y</th>\n",
       "      <th>time_signature_y</th>\n",
       "      <th>valence_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69879</th>\n",
       "      <td>2TphHnGFkdWgARmEz2aEM9</td>\n",
       "      <td>Tosca / Act 3: Introduzione all'aria ... E luc...</td>\n",
       "      <td>Giacomo Puccini: Tosca</td>\n",
       "      <td>Leontyne Price</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.194</td>\n",
       "      <td>249827.0</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>E</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>-23.493</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>86.987</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.0377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69880</th>\n",
       "      <td>6sA1rk1FILT7DhnrQcD5AA</td>\n",
       "      <td>Not For Me - Remastered 2002</td>\n",
       "      <td>18 Yellow Roses</td>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.653</td>\n",
       "      <td>142560.0</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>G#</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>-11.645</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>116.642</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69881</th>\n",
       "      <td>6sA1rk1FILT7DhnrQcD5AA</td>\n",
       "      <td>Not For Me - Remastered 2002</td>\n",
       "      <td>18 Yellow Roses</td>\n",
       "      <td>Bobby Darin</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.653</td>\n",
       "      <td>142560.0</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>G#</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>-11.645</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>116.642</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.7180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69882</th>\n",
       "      <td>6jjXwmG1czQP9krzlFsaDw</td>\n",
       "      <td>Stop the Wedding</td>\n",
       "      <td>Etta James Top Ten</td>\n",
       "      <td>Etta James</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.416</td>\n",
       "      <td>166661.0</td>\n",
       "      <td>0.3530</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3530</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>A#</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>-9.482</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>173.064</td>\n",
       "      <td>3/4</td>\n",
       "      <td>0.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69883</th>\n",
       "      <td>093adSf9ll30BEpggrfask</td>\n",
       "      <td>Foolish Little Girl</td>\n",
       "      <td>Foolish Little Girl</td>\n",
       "      <td>The Shirelles</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.739</td>\n",
       "      <td>137293.0</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>G</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>-5.926</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>111.070</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "69879  2TphHnGFkdWgARmEz2aEM9   \n",
       "69880  6sA1rk1FILT7DhnrQcD5AA   \n",
       "69881  6sA1rk1FILT7DhnrQcD5AA   \n",
       "69882  6jjXwmG1czQP9krzlFsaDw   \n",
       "69883  093adSf9ll30BEpggrfask   \n",
       "\n",
       "                                                    song  \\\n",
       "69879  Tosca / Act 3: Introduzione all'aria ... E luc...   \n",
       "69880                       Not For Me - Remastered 2002   \n",
       "69881                       Not For Me - Remastered 2002   \n",
       "69882                                   Stop the Wedding   \n",
       "69883                                Foolish Little Girl   \n",
       "\n",
       "                        album          artist  acousticness_x  danceability_x  \\\n",
       "69879  Giacomo Puccini: Tosca  Leontyne Price           0.927           0.194   \n",
       "69880         18 Yellow Roses     Bobby Darin           0.526           0.653   \n",
       "69881         18 Yellow Roses     Bobby Darin           0.526           0.653   \n",
       "69882      Etta James Top Ten      Etta James           0.850           0.416   \n",
       "69883     Foolish Little Girl   The Shirelles           0.452           0.739   \n",
       "\n",
       "       duration_ms_x  energy_x  instrumentalness_x  key_x  ...  energy_y  \\\n",
       "69879       249827.0    0.0926            0.376000    4.0  ...    0.0926   \n",
       "69880       142560.0    0.4120            0.000000    8.0  ...    0.4120   \n",
       "69881       142560.0    0.4120            0.000000    8.0  ...    0.4120   \n",
       "69882       166661.0    0.3530            0.000178   10.0  ...    0.3530   \n",
       "69883       137293.0    0.7430            0.000000    7.0  ...    0.7430   \n",
       "\n",
       "       instrumentalness_y  key_y  liveness_y  loudness_y  mode_y  \\\n",
       "69879            0.376000      E      0.0881     -23.493   Minor   \n",
       "69880            0.000000     G#      0.0714     -11.645   Major   \n",
       "69881            0.000000     G#      0.0714     -11.645   Major   \n",
       "69882            0.000178     A#      0.2870      -9.482   Major   \n",
       "69883            0.000000      G      0.3310      -5.926   Minor   \n",
       "\n",
       "       speechiness_y  tempo_y time_signature_y valence_y  \n",
       "69879         0.0395   86.987              4/4    0.0377  \n",
       "69880         0.0485  116.642              4/4    0.7180  \n",
       "69881         0.0485  116.642              4/4    0.7180  \n",
       "69882         0.0400  173.064              3/4    0.6650  \n",
       "69883         0.0321  111.070              4/4    0.9220  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.merge(data, left_on='id', right_on='track_id').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotipy\n",
    "\n",
    "In order to, on the one hand, use a data source with many records and, on the other hand, use a rich data source with many features, we will utilize the Spotipy API to fetch additional information about every song present in the first dataset, discarding the second, since we won't be needing its additional features.\n",
    "\n",
    "First of all we connect to Spotipy with the credentials given to us by Spotify for Developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "cid =\"XXXXXXXXXXXXXXXXXXXXXXXXX\" \n",
    "secret = \"XXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample query\n",
    "\n",
    "We test the connection by fetching information about the first record in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009-04-06'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json = sp.track(data.track_id[0])\n",
    "json['album']['release_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Crawiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotipy allows us to request information for up to 50 songs per query, so we divide the dataset into chunks of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "\n",
    "ids = list(chunks(data.track_id.to_list(), 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information quering\n",
    "\n",
    "Below is the code that fetches the additional information for every record. We fetch:\n",
    "* the \"explicit\" boolean feature (dictating if a song contains inappropriate words),\n",
    "* the release date and\n",
    "* the name of the album\n",
    "\n",
    "That information is inserted in three dictionaries, which have the songs' IDs as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explicit = {}\n",
    "dates = {}\n",
    "album_names = {}\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    #if i%50==0: #status update\n",
    "    #    print(i, '/', len(ids))\n",
    "    jsons = sp.tracks(ids[i])['tracks']\n",
    "    for json in jsons:\n",
    "        tr_id = json['id']\n",
    "        explicit[tr_id] = json['explicit']\n",
    "        album_names[tr_id] = json['album']['name']\n",
    "        dates[tr_id] = json['album']['release_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the new features to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['explicit'] = [explicit[x] for x in data.track_id]\n",
    "data['album_release'] = [dates[x] for x in data.track_id]\n",
    "data['album_name'] = [album_names[x] for x in data.track_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>explicit</th>\n",
       "      <th>album_release</th>\n",
       "      <th>album_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>Dance</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>Get the Party Started</td>\n",
       "      <td>2u1hMwcB9TwziV6P7jdyxX</td>\n",
       "      <td>66</td>\n",
       "      <td>0.00127</td>\n",
       "      <td>0.806</td>\n",
       "      <td>191667</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212</td>\n",
       "      <td>-3.387</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>128.943</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.961</td>\n",
       "      <td>False</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>M!ssundaztood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       genre artist_name             track_name                track_id  \\\n",
       "14985  Dance        P!nk  Get the Party Started  2u1hMwcB9TwziV6P7jdyxX   \n",
       "\n",
       "       popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "14985          66       0.00127         0.806       191667   0.902   \n",
       "\n",
       "       instrumentalness  ... liveness  loudness   mode speechiness    tempo  \\\n",
       "14985               0.0  ...    0.212    -3.387  Minor      0.0475  128.943   \n",
       "\n",
       "       time_signature valence  explicit  album_release     album_name  \n",
       "14985             4/4   0.961     False     2001-01-01  M!ssundaztood  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas did not automatically cast the release date into a datetime type, so we will need to do that manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.album_release.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['album_release'] = pd.to_datetime(data['album_release'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting some invalid values, by looking up the correct ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = data.album_release.min()\n",
    "data.loc[data.album_release.values == min, 'album_release'] = [2017]*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking DataFrame's data completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre               0\n",
       "artist_name         0\n",
       "track_name          0\n",
       "track_id            0\n",
       "popularity          0\n",
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "valence             0\n",
       "explicit            0\n",
       "album_release       0\n",
       "album_name          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting our work into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('songs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining\n",
    "\n",
    "We have our dataset ready, so we move forward with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sound Wave Popularity\n",
    "\n",
    "The first data analysis application will be popularity prediction; a common application among song analytics. The best predictors, when it comes to song popularity, are probably the artist, the label and the genre. With that being said, we will use a different approach. Wouldn't it be interesting to research and find the fundamental, inherent, *musical* characteristics that make a song popular?\n",
    "\n",
    "Yes, we know that if Kanye West releases a song it will be popular, but it would be more interesting to know if, for example, a song that has a higher danceability is destined for success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('songs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Starting simple, aiming to not only predict a single number, but realise the musical dynamics between musical features and popularity, we will use a simple linear regression model. It will allow us to see which features impact the overall score the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.graphics as sgr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smf.ols('popularity ~ acousticness + danceability + energy'\n",
    "              '+ instrumentalness + liveness + loudness + speechiness + tempo + valence', data=data)\n",
    "model = mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression results\n",
    "\n",
    "We can see that the $R^2$ value is a bit low, but it is enough for us to reach some conclusions, in conjuction with the low P-values.\n",
    "\n",
    "Keeping in mind that all the values are numbers between 0 and 1, the danceability seems to be the feature that *increases* popularity the most. It is a logical result, since a song that makes us dance will probably be used more in clubs, bars and parties, and will be shared more among social circles and social media.\n",
    "\n",
    "On the contrary, we can see how a high acousticness score can greatly *reduce* the popularity. So, songs with artificial, electrical sounds (like electric guitars, drums and auto-tuned vocals) are more popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>popularity</td>    <th>  R-squared:         </th>  <td>   0.234</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.234</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7885.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 07 Jan 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:29:01</td>     <th>  Log-Likelihood:    </th> <td>-9.7436e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>232725</td>      <th>  AIC:               </th>  <td>1.949e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>232715</td>      <th>  BIC:               </th>  <td>1.949e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   56.1133</td> <td>    0.334</td> <td>  168.025</td> <td> 0.000</td> <td>   55.459</td> <td>   56.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>  -11.9865</td> <td>    0.155</td> <td>  -77.511</td> <td> 0.000</td> <td>  -12.290</td> <td>  -11.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>   17.6225</td> <td>    0.242</td> <td>   72.883</td> <td> 0.000</td> <td>   17.149</td> <td>   18.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>   -5.6151</td> <td>    0.279</td> <td>  -20.093</td> <td> 0.000</td> <td>   -6.163</td> <td>   -5.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>   -4.2721</td> <td>    0.133</td> <td>  -32.123</td> <td> 0.000</td> <td>   -4.533</td> <td>   -4.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness</th>         <td>   -9.6241</td> <td>    0.201</td> <td>  -47.856</td> <td> 0.000</td> <td>  -10.018</td> <td>   -9.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>    0.7152</td> <td>    0.011</td> <td>   63.495</td> <td> 0.000</td> <td>    0.693</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>   -8.1187</td> <td>    0.230</td> <td>  -35.316</td> <td> 0.000</td> <td>   -8.569</td> <td>   -7.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>   -0.0045</td> <td>    0.001</td> <td>   -4.031</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence</th>          <td>  -13.3513</td> <td>    0.165</td> <td>  -80.753</td> <td> 0.000</td> <td>  -13.675</td> <td>  -13.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4295.836</td> <th>  Durbin-Watson:     </th> <td>   0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4535.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.341</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.953</td>  <th>  Cond. No.          </th> <td>1.67e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.67e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             popularity   R-squared:                       0.234\n",
       "Model:                            OLS   Adj. R-squared:                  0.234\n",
       "Method:                 Least Squares   F-statistic:                     7885.\n",
       "Date:                Tue, 07 Jan 2020   Prob (F-statistic):               0.00\n",
       "Time:                        01:29:01   Log-Likelihood:            -9.7436e+05\n",
       "No. Observations:              232725   AIC:                         1.949e+06\n",
       "Df Residuals:                  232715   BIC:                         1.949e+06\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           56.1133      0.334    168.025      0.000      55.459      56.768\n",
       "acousticness       -11.9865      0.155    -77.511      0.000     -12.290     -11.683\n",
       "danceability        17.6225      0.242     72.883      0.000      17.149      18.096\n",
       "energy              -5.6151      0.279    -20.093      0.000      -6.163      -5.067\n",
       "instrumentalness    -4.2721      0.133    -32.123      0.000      -4.533      -4.011\n",
       "liveness            -9.6241      0.201    -47.856      0.000     -10.018      -9.230\n",
       "loudness             0.7152      0.011     63.495      0.000       0.693       0.737\n",
       "speechiness         -8.1187      0.230    -35.316      0.000      -8.569      -7.668\n",
       "tempo               -0.0045      0.001     -4.031      0.000      -0.007      -0.002\n",
       "valence            -13.3513      0.165    -80.753      0.000     -13.675     -13.027\n",
       "==============================================================================\n",
       "Omnibus:                     4295.836   Durbin-Watson:                   0.447\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4535.133\n",
       "Skew:                          -0.341   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.953   Cond. No.                     1.67e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.67e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Provided that we limit the possible features, that will be used in the model, to musical ones, which of those help us achieve the best possible prediction? That is what we will try to find in the below- adopted- cell, by using all the possible combinations of those features and trying to find the combination that maximizes the adjusted $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subset(y, data, feature_set):\n",
    "    X = data.loc[:, feature_set].values\n",
    "    X = sm.add_constant(X)\n",
    "    names = ['intercept']\n",
    "    names.extend(feature_set)\n",
    "    model = sm.OLS(y, X)\n",
    "    model.data.xnames = names\n",
    "    regr = model.fit()\n",
    "    return regr\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_best_of_k(y, data, k):\n",
    "    \n",
    "    best_rsquared = 0\n",
    "    best_model = None\n",
    "    for comb in itertools.combinations(data.columns, k):\n",
    "        regr = process_subset(y, data, comb)\n",
    "        if regr.rsquared > best_rsquared:\n",
    "            best_rsquared = regr.rsquared\n",
    "            best_model = regr\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def best_subset_selection(data, exog):\n",
    "    best_model = None\n",
    "    best_models = []\n",
    "    y = data.loc[:, exog]\n",
    "    endog = [ x for x in data.columns if x != exog ]\n",
    "    X = data.loc[:, endog]\n",
    "\n",
    "    for i in range(1, len(data.columns)):\n",
    "        print(f'Finding the best model for {i} variable{\"s\" if i > 1 else \"\"}')\n",
    "        model = get_best_of_k(y, X, i)\n",
    "        if not best_model or model.rsquared_adj > best_model.rsquared_adj:\n",
    "            best_model = model\n",
    "        print(model.model.data.xnames[1:])\n",
    "        best_models.append(model)\n",
    "\n",
    "    print(f'Fitted {2**len(data.columns)} models')\n",
    "    return best_model, best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first model, we arbitrarily selected the feature combination that includes all the possible features and it turns out that it is the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the best model for 1 variable\n",
      "['acousticness']\n",
      "Finding the best model for 2 variables\n",
      "['liveness', 'loudness']\n",
      "Finding the best model for 3 variables\n",
      "['acousticness', 'energy', 'loudness']\n",
      "Finding the best model for 4 variables\n",
      "['acousticness', 'energy', 'liveness', 'loudness']\n",
      "Finding the best model for 5 variables\n",
      "['acousticness', 'danceability', 'liveness', 'loudness', 'valence']\n",
      "Finding the best model for 6 variables\n",
      "['acousticness', 'danceability', 'liveness', 'loudness', 'speechiness', 'valence']\n",
      "Finding the best model for 7 variables\n",
      "['acousticness', 'danceability', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'valence']\n",
      "Finding the best model for 8 variables\n",
      "['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'valence']\n",
      "Finding the best model for 9 variables\n",
      "['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo', 'valence']\n",
      "Fitted 1024 models\n"
     ]
    }
   ],
   "source": [
    "best_model, _ = best_subset_selection(data.iloc[:,[4,5,6,8,9,11,12,14,15,17]], 'popularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means that the summary of the best model, found below, is the same as the one analysed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>popularity</td>    <th>  R-squared:         </th>  <td>   0.234</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.234</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7885.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 06 Jan 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:22:16</td>     <th>  Log-Likelihood:    </th> <td>-9.7436e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>232725</td>      <th>  AIC:               </th>  <td>1.949e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>232715</td>      <th>  BIC:               </th>  <td>1.949e+06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>   56.1133</td> <td>    0.334</td> <td>  168.025</td> <td> 0.000</td> <td>   55.459</td> <td>   56.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>acousticness</th>     <td>  -11.9865</td> <td>    0.155</td> <td>  -77.511</td> <td> 0.000</td> <td>  -12.290</td> <td>  -11.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th>     <td>   17.6225</td> <td>    0.242</td> <td>   72.883</td> <td> 0.000</td> <td>   17.149</td> <td>   18.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>           <td>   -5.6151</td> <td>    0.279</td> <td>  -20.093</td> <td> 0.000</td> <td>   -6.163</td> <td>   -5.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instrumentalness</th> <td>   -4.2721</td> <td>    0.133</td> <td>  -32.123</td> <td> 0.000</td> <td>   -4.533</td> <td>   -4.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>liveness</th>         <td>   -9.6241</td> <td>    0.201</td> <td>  -47.856</td> <td> 0.000</td> <td>  -10.018</td> <td>   -9.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>         <td>    0.7152</td> <td>    0.011</td> <td>   63.495</td> <td> 0.000</td> <td>    0.693</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>speechiness</th>      <td>   -8.1187</td> <td>    0.230</td> <td>  -35.316</td> <td> 0.000</td> <td>   -8.569</td> <td>   -7.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>            <td>   -0.0045</td> <td>    0.001</td> <td>   -4.031</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence</th>          <td>  -13.3513</td> <td>    0.165</td> <td>  -80.753</td> <td> 0.000</td> <td>  -13.675</td> <td>  -13.027</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4295.836</td> <th>  Durbin-Watson:     </th> <td>   0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4535.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.341</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.953</td>  <th>  Cond. No.          </th> <td>1.67e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.67e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             popularity   R-squared:                       0.234\n",
       "Model:                            OLS   Adj. R-squared:                  0.234\n",
       "Method:                 Least Squares   F-statistic:                     7885.\n",
       "Date:                Mon, 06 Jan 2020   Prob (F-statistic):               0.00\n",
       "Time:                        21:22:16   Log-Likelihood:            -9.7436e+05\n",
       "No. Observations:              232725   AIC:                         1.949e+06\n",
       "Df Residuals:                  232715   BIC:                         1.949e+06\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "intercept           56.1133      0.334    168.025      0.000      55.459      56.768\n",
       "acousticness       -11.9865      0.155    -77.511      0.000     -12.290     -11.683\n",
       "danceability        17.6225      0.242     72.883      0.000      17.149      18.096\n",
       "energy              -5.6151      0.279    -20.093      0.000      -6.163      -5.067\n",
       "instrumentalness    -4.2721      0.133    -32.123      0.000      -4.533      -4.011\n",
       "liveness            -9.6241      0.201    -47.856      0.000     -10.018      -9.230\n",
       "loudness             0.7152      0.011     63.495      0.000       0.693       0.737\n",
       "speechiness         -8.1187      0.230    -35.316      0.000      -8.569      -7.668\n",
       "tempo               -0.0045      0.001     -4.031      0.000      -0.007      -0.002\n",
       "valence            -13.3513      0.165    -80.753      0.000     -13.675     -13.027\n",
       "==============================================================================\n",
       "Omnibus:                     4295.836   Durbin-Watson:                   0.447\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4535.133\n",
       "Skew:                          -0.341   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.953   Cond. No.                     1.67e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.67e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor\n",
    "\n",
    "We will continue looking into the same application, but we will change into a more advanced predictory model; the Decision Tree Regressor. The application is more complex than we gave it credit for, above. The tree will allow us to handle the multi co-linearity better, while also allowing us to have some basic form of model visualization, just for the sake of it; it is supposed to be a fun work after all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  acousticness  danceability  energy  instrumentalness  liveness  \\\n",
       "0           0         0.611         0.389   0.910             0.000    0.3460   \n",
       "1           1         0.246         0.590   0.737             0.000    0.1510   \n",
       "2           3         0.952         0.663   0.131             0.000    0.1030   \n",
       "3           0         0.703         0.240   0.326             0.000    0.0985   \n",
       "4           4         0.950         0.331   0.225             0.123    0.2020   \n",
       "\n",
       "   loudness  speechiness    tempo  valence  \n",
       "0    -1.828       0.0525  166.969    0.814  \n",
       "1    -5.559       0.0868  174.003    0.816  \n",
       "2   -13.879       0.0362   99.488    0.368  \n",
       "3   -12.178       0.0395  171.758    0.227  \n",
       "4   -21.150       0.0456  140.576    0.390  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = data.iloc[:, [4,5,6,8,9,11,12,14,15,17]]\n",
    "columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split the dataset into 80%-20%, train and test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = columns.iloc[:, 1:], columns.popularity\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Mean Absolute Error as the criterion and we will limit the fit to a maximum depth of 5, using only the first 100.000 records, allowing for a fitting in a resonable time, with our limited resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mae', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_rgr = DecisionTreeRegressor(criterion='mae', max_depth=5)\n",
    "\n",
    "tree_rgr.fit(X_train[:100000], y_train[:100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will calculate the MAE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree_rgr.predict(X_test)\n",
    "mae = metrics.mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the tree into an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image  \n",
    "from IPython.display import display\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(tree_rgr, out_file=dot_data,  \n",
    "                     feature_names=columns.columns[1:],  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png()) \n",
    "\n",
    "graph = graphviz.Source(tree.export_graphviz(tree_rgr, max_depth=3, feature_names=columns.columns[1:], rounded=True,   filled=True, special_characters=True))\n",
    "\n",
    "graph.format = \"png\"\n",
    "graph.render(\"graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see our tree.\n",
    "<img src='images/graph.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing our model's MAE to a baseline; just guessing the mean popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23407699868689225\n",
      "14.84425210294308\n"
     ]
    }
   ],
   "source": [
    "print(metrics.mean_absolute_error(y_test, tree_rgr.predict(X_test)))\n",
    "print(metrics.mean_absolute_error(y_test, [y_train.mean()]*len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a random value to see what our model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randrange\n",
    "rand = randrange(len(X_test))\n",
    "tree_rgr.predict([X_test[rand]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[rand]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genre Prediction\n",
    "\n",
    "The second application we will work on is genre prediction. This time we will use all of the available features, with the goal of classifying a song into one- or more- genres. To do that we will utilise a neural network, since they fare well with multi-label classification applications.\n",
    "\n",
    "Below we will correct some genre data and, also, turn our categorical variables into k-hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "data = pd.read_csv('songs.csv')\n",
    "data.loc[data.genre=='Children’s Music', 'genre'] = 'Children\\'s Music'\n",
    "data = pd.get_dummies(data, columns=['mode', 'explicit'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use MultiLabelBinarizer to create a 26-hot encoded DataFrame with the genres that a song belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n",
       "       'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo',\n",
       "       'valence', 'mode_Minor', 'explicit_True'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "classes = mlb.fit_transform([[x] for x in data.genre])\n",
    "\n",
    "X, y = data.iloc[:, [4,5,6,7,8,9,11,12,13,14,16,19,20]], classes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2, shuffle=True)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple network will be used.\n",
    "* The first layer is a Dense one, of 32 neurons, with each one of those having the 13 features as input.\n",
    "* Next there is the dropout layer, to limit over-fitting.\n",
    "* Thirdly, there is a second Dense layer, of 16 neurons. The Dense layers seemed to provide better results with the relu activation function.\n",
    "* Lastly we have the classification layer, with 26 neurons (the number of classes we try to predict) and a sigmoid activation function, since we have a multi label classification application. For the same reason, the loss function is binary crossentropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                442       \n",
      "=================================================================\n",
      "Total params: 1,418\n",
      "Trainable params: 1,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model_simple = Sequential([\n",
    "    Dense(32, input_shape=(13,), activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(NUM_CLASSES, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_simple.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the network's structure better, we can see it visualized below. 20% of the neuron connections between the two hidden layers are discarded in each epoch (due to the Dropout).\n",
    "\n",
    "<img src='images/network_pic.png' width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy may seem quite high, but it is skewed because of the many zeroes present in the prediction. Basically, if we guess that a song does not belong in any class we are more than 90% correct, since it may belong to one or two genres, out of the twenty six."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 186180 samples, validate on 46545 samples\n",
      "Epoch 1/2\n",
      "186180/186180 [==============================] - 79s 423us/sample - loss: 108.8968 - accuracy: 0.9261 - val_loss: 0.3083 - val_accuracy: 0.9322\n",
      "Epoch 2/2\n",
      "186180/186180 [==============================] - 62s 332us/sample - loss: 0.2540 - accuracy: 0.9580 - val_loss: 0.1613 - val_accuracy: 0.9615\n"
     ]
    }
   ],
   "source": [
    "simple_history = model_simple.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Performance\n",
    "\n",
    "To improve our assesment of the network's performance, we will use the test dataset again. The predictions are 26 numbers [0, 1], describing how probable it is for that song to belong in that specific genre. Thus, we will change them into binaries, by using a treshold, accepting predictions with a higher number that the treshold as actual genres of that song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00260785 0.04031795 0.038791   0.03842062 0.06280309 0.03958815\n",
      " 0.04268703 0.03735015 0.03785449 0.04189181 0.04028147 0.04109302\n",
      " 0.04069251 0.04147059 0.03397501 0.03635618 0.04104292 0.03943545\n",
      " 0.03880572 0.0384241  0.03909135 0.04151443 0.03918499 0.04091018\n",
      " 0.04250628 0.0393123 ]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "treshold = 0.05\n",
    "pred_test_std = model_simple.predict(X_test)\n",
    "\n",
    "pred_ar = pred_test_std[0]\n",
    "print(pred_ar)\n",
    "for position, prediction in enumerate(pred_ar):\n",
    "    if prediction > treshold:\n",
    "        pred_ar[position] = 1\n",
    "    else:\n",
    "        pred_ar[position] = 0\n",
    "print(pred_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Music\n",
    "\n",
    "We will explore some visualizations of our data below.\n",
    "\n",
    "*Note:* I wanted to experiment with PowerBI, so the visualizations are prepared there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rock Titles\n",
    "We will start off with a visualization of the songs' titles, focusing on titles from Rock songs.\n",
    "\n",
    "We will read the data, correct the wrong genre data and then split the titles into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('songs.csv')\n",
    "data.loc[data.genre=='Children’s Music', 'genre'] = 'Children\\'s Music'\n",
    "\n",
    "words = data.loc[data.genre=='Rock'].track_name.str.split()\n",
    "\n",
    "reshaped_words = np.reshape(words.tolist(), (1,-1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to keep the words from each title separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for word in reshaped_words:\n",
    "    words += word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the number each specific word was used in all of the available titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wors = pd.Series(filtered_words).value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually removing words that do not add something to our visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wors.drop('2011', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Love     336\n",
       "Live     111\n",
       "Man       95\n",
       "One       84\n",
       "Good      83\n",
       "Night     79\n",
       "Life      79\n",
       "Time      78\n",
       "Song      77\n",
       "Go        75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wors.head(10)#.to_csv('words_rock.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having prepared the list with the most common words, and their respective number of uses, it is easy to create a word cloud on PowerBI, as seen below.\n",
    "\n",
    "<img src='images/rock.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for any other genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Movie', 'R&B', 'A Capella', 'Alternative', 'Country', 'Dance',\n",
       "       'Electronic', 'Anime', 'Folk', 'Blues', 'Opera', 'Hip-Hop',\n",
       "       \"Children's Music\", 'Rap', 'Indie', 'Classical', 'Pop', 'Reggae',\n",
       "       'Reggaeton', 'Jazz', 'Rock', 'Ska', 'Comedy', 'Soul', 'Soundtrack',\n",
       "       'World'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.genre.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Visualizations\n",
    "\n",
    "I experimented with an SQL DB, which was used to make the below visualizations, but they were interesting enough to be included in this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valence & Danceability\n",
    "We can see the average valence and danceability, by decade (*note:* the records from the 1880s, 1890s and the 1900s are few).<br>They seem to be following the same trends, with an interesting observation beeing the two major dips, during the two World Wars.\n",
    "<img src='images/danc_val.png' width='750'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy & Loudness\n",
    "\n",
    "Similarly to Valence & Danceability, the Energy & the Loudness of a song follow similar trends. Granted, those two features are highly correlated, but energy, besides loudness, describes dynamic range, timbre, onset rate, and general entropy.\n",
    "\n",
    "We can see once again the effect the two World Wars had on music. However, even though there were some dips on those two metrics during WWI and WWII, currently they seem to be at their highest level, proving the fact that people nowadays are mostly interested about loud, fast and sense-hightening, dopamine-releasing music.\n",
    "\n",
    "<img src='images/energy.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Artists\n",
    "The artists that had the highest average popularity, for the 4 most popular genres (provided that they had at least 5 songs in that genre).\n",
    "\n",
    "<img src='images/topArtists.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computerizing Music\n",
    "\n",
    "The average acousticness seems to be steadily dropping. As we saw above, the acousticness score seems to be reducing the popularity score greatly, with people prefering artificial sounds, so limiting acousticness is to be expected from artists.\n",
    "\n",
    "<img src='images/acousticness.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
